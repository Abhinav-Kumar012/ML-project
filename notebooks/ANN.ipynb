{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:33:51.037597: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 12:33:51.064891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733900631.096297  197036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733900631.105514  197036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 12:33:51.130889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder,OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('../input/credit-dset/clean_trained.csv')\n",
    "df_test = pd.read_csv('../input/credit-dset/test_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encode_cols = ['Month','Profession']\n",
    "for i in one_hot_encode_cols:\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    encoded_train = ohe.fit_transform(df_train[[i]])\n",
    "    encoded_test = ohe.transform(df_test[[i]])\n",
    "    encoded_cols = [f\"{i}_{j}\" for j in ohe.categories_[0]]\n",
    "    df_train_encoded = pd.DataFrame(encoded_train, columns=encoded_cols)\n",
    "    df_test_encoded = pd.DataFrame(encoded_test, columns=encoded_cols)\n",
    "    df_train = pd.concat([df_train, df_train_encoded], axis=1).drop(columns=[i])\n",
    "    df_test = pd.concat([df_test, df_test_encoded], axis=1).drop(columns=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_mix_dict = {\"Bad\" : 0,\"Standard\" : 1,\"Good\" : 2}\n",
    "df_train['Credit_Mix'] = df_train['Credit_Mix'].map(cred_mix_dict)\n",
    "df_test['Credit_Mix'] = df_test['Credit_Mix'].map(cred_mix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['pay_type','val_pay']] = df_train['Payment_Behaviour'].str.split(pat = '_spent_',n=1,expand = True)\n",
    "df_test[['pay_type','val_pay']] = df_test['Payment_Behaviour'].str.split(pat = '_spent_',n=1,expand = True)\n",
    "df_train = df_train.drop(['Payment_Behaviour'],axis=1)\n",
    "df_test = df_test.drop(['Payment_Behaviour'],axis=1)\n",
    "pay_type_dict = {'Low' : 0, 'High' : 1}\n",
    "val_pay_dict = {'Small_value_payments' : 0,'Medium_value_payments' : 1,'Large_value_payments' : 2}\n",
    "df_train['pay_type'] = df_train['pay_type'].map(pay_type_dict)\n",
    "df_test['pay_type'] = df_test['pay_type'].map(pay_type_dict)\n",
    "df_train['val_pay'] = df_train['val_pay'].map(val_pay_dict)\n",
    "df_test['val_pay'] = df_test['val_pay'].map(val_pay_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_dict = {'Yes' : 1,'No' : 0}\n",
    "df_train['Payment_of_Min_Amount'] = df_train['Payment_of_Min_Amount'].map(yes_no_dict)\n",
    "df_test['Payment_of_Min_Amount'] = df_test['Payment_of_Min_Amount'].map(yes_no_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final = OrdinalEncoder(categories=[['Poor', 'Standard', 'Good']])\n",
    "df_train['Credit_Score'] = encoder_final.fit_transform(df_train[['Credit_Score']])\n",
    "df_train['Credit_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['Credit_Score','Number'],axis=1)\n",
    "Y = df_train['Credit_Score']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_test=df_test.drop(['Number'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = X_scaled.reshape(-1, X_scaled.shape[1], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:33:54.336492: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.4552 - loss: 1.8368 - val_accuracy: 0.5842 - val_loss: 1.5471\n",
      "Epoch 2/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5710 - loss: 1.5294 - val_accuracy: 0.6104 - val_loss: 1.4325\n",
      "Epoch 3/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6147 - loss: 1.4376 - val_accuracy: 0.6276 - val_loss: 1.3487\n",
      "Epoch 4/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6273 - loss: 1.3800 - val_accuracy: 0.6502 - val_loss: 1.3012\n",
      "Epoch 5/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6370 - loss: 1.3366 - val_accuracy: 0.6598 - val_loss: 1.2681\n",
      "Epoch 6/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6423 - loss: 1.3034 - val_accuracy: 0.6649 - val_loss: 1.2452\n",
      "Epoch 7/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6485 - loss: 1.2758 - val_accuracy: 0.6662 - val_loss: 1.2252\n",
      "Epoch 8/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6511 - loss: 1.2531 - val_accuracy: 0.6674 - val_loss: 1.2055\n",
      "Epoch 9/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6528 - loss: 1.2273 - val_accuracy: 0.6682 - val_loss: 1.1834\n",
      "Epoch 10/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6537 - loss: 1.2051 - val_accuracy: 0.6681 - val_loss: 1.1635\n",
      "Epoch 11/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6569 - loss: 1.1829 - val_accuracy: 0.6701 - val_loss: 1.1453\n",
      "Epoch 12/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6627 - loss: 1.1593 - val_accuracy: 0.6708 - val_loss: 1.1296\n",
      "Epoch 13/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.6659 - loss: 1.1377 - val_accuracy: 0.6721 - val_loss: 1.1099\n",
      "Epoch 14/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6616 - loss: 1.1194 - val_accuracy: 0.6730 - val_loss: 1.0928\n",
      "Epoch 15/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6659 - loss: 1.0968 - val_accuracy: 0.6722 - val_loss: 1.0723\n",
      "Epoch 16/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6683 - loss: 1.0767 - val_accuracy: 0.6744 - val_loss: 1.0553\n",
      "Epoch 17/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6692 - loss: 1.0590 - val_accuracy: 0.6726 - val_loss: 1.0375\n",
      "Epoch 18/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6691 - loss: 1.0394 - val_accuracy: 0.6731 - val_loss: 1.0189\n",
      "Epoch 19/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6709 - loss: 1.0214 - val_accuracy: 0.6756 - val_loss: 1.0025\n",
      "Epoch 20/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6750 - loss: 0.9993 - val_accuracy: 0.6741 - val_loss: 0.9858\n",
      "Epoch 21/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6717 - loss: 0.9820 - val_accuracy: 0.6736 - val_loss: 0.9699\n",
      "Epoch 22/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6768 - loss: 0.9622 - val_accuracy: 0.6752 - val_loss: 0.9531\n",
      "Epoch 23/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6782 - loss: 0.9458 - val_accuracy: 0.6753 - val_loss: 0.9396\n",
      "Epoch 24/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6772 - loss: 0.9266 - val_accuracy: 0.6737 - val_loss: 0.9219\n",
      "Epoch 25/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6802 - loss: 0.9108 - val_accuracy: 0.6759 - val_loss: 0.9106\n",
      "Epoch 26/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6795 - loss: 0.8957 - val_accuracy: 0.6749 - val_loss: 0.8941\n",
      "Epoch 27/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.6812 - loss: 0.8804 - val_accuracy: 0.6739 - val_loss: 0.8827\n",
      "Epoch 28/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.6789 - loss: 0.8694 - val_accuracy: 0.6768 - val_loss: 0.8688\n",
      "Epoch 29/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6845 - loss: 0.8528 - val_accuracy: 0.6753 - val_loss: 0.8566\n",
      "Epoch 30/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.6822 - loss: 0.8424 - val_accuracy: 0.6756 - val_loss: 0.8462\n",
      "Epoch 31/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.6836 - loss: 0.8297 - val_accuracy: 0.6746 - val_loss: 0.8385\n",
      "Epoch 32/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6844 - loss: 0.8215 - val_accuracy: 0.6751 - val_loss: 0.8299\n",
      "Epoch 33/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6825 - loss: 0.8108 - val_accuracy: 0.6779 - val_loss: 0.8185\n",
      "Epoch 34/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6864 - loss: 0.7994 - val_accuracy: 0.6780 - val_loss: 0.8110\n",
      "Epoch 35/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6865 - loss: 0.7896 - val_accuracy: 0.6771 - val_loss: 0.8057\n",
      "Epoch 36/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6876 - loss: 0.7827 - val_accuracy: 0.6759 - val_loss: 0.8017\n",
      "Epoch 37/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6890 - loss: 0.7774 - val_accuracy: 0.6764 - val_loss: 0.7934\n",
      "Epoch 38/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6894 - loss: 0.7683 - val_accuracy: 0.6785 - val_loss: 0.7884\n",
      "Epoch 39/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6893 - loss: 0.7626 - val_accuracy: 0.6766 - val_loss: 0.7840\n",
      "Epoch 40/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6928 - loss: 0.7574 - val_accuracy: 0.6766 - val_loss: 0.7821\n",
      "Epoch 41/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6913 - loss: 0.7500 - val_accuracy: 0.6759 - val_loss: 0.7794\n",
      "Epoch 42/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6940 - loss: 0.7496 - val_accuracy: 0.6779 - val_loss: 0.7722\n",
      "Epoch 43/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6952 - loss: 0.7420 - val_accuracy: 0.6781 - val_loss: 0.7703\n",
      "Epoch 44/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6937 - loss: 0.7392 - val_accuracy: 0.6776 - val_loss: 0.7679\n",
      "Epoch 45/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6954 - loss: 0.7364 - val_accuracy: 0.6769 - val_loss: 0.7673\n",
      "Epoch 46/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6983 - loss: 0.7306 - val_accuracy: 0.6754 - val_loss: 0.7645\n",
      "Epoch 47/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6952 - loss: 0.7302 - val_accuracy: 0.6784 - val_loss: 0.7615\n",
      "Epoch 48/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6961 - loss: 0.7271 - val_accuracy: 0.6781 - val_loss: 0.7604\n",
      "Epoch 49/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6952 - loss: 0.7237 - val_accuracy: 0.6799 - val_loss: 0.7574\n",
      "Epoch 50/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6981 - loss: 0.7186 - val_accuracy: 0.6758 - val_loss: 0.7576\n",
      "Epoch 51/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6984 - loss: 0.7144 - val_accuracy: 0.6766 - val_loss: 0.7562\n",
      "Epoch 52/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.6990 - loss: 0.7153 - val_accuracy: 0.6750 - val_loss: 0.7568\n",
      "Epoch 53/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.6982 - loss: 0.7139 - val_accuracy: 0.6772 - val_loss: 0.7541\n",
      "Epoch 54/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7005 - loss: 0.7097 - val_accuracy: 0.6775 - val_loss: 0.7530\n",
      "Epoch 55/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7043 - loss: 0.7083 - val_accuracy: 0.6767 - val_loss: 0.7534\n",
      "Epoch 56/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7041 - loss: 0.7030 - val_accuracy: 0.6800 - val_loss: 0.7523\n",
      "Epoch 57/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7044 - loss: 0.7008 - val_accuracy: 0.6765 - val_loss: 0.7522\n",
      "Epoch 58/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7063 - loss: 0.6975 - val_accuracy: 0.6768 - val_loss: 0.7515\n",
      "Epoch 59/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7058 - loss: 0.6999 - val_accuracy: 0.6758 - val_loss: 0.7512\n",
      "Epoch 60/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7077 - loss: 0.6972 - val_accuracy: 0.6760 - val_loss: 0.7521\n",
      "Epoch 61/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7078 - loss: 0.6963 - val_accuracy: 0.6768 - val_loss: 0.7529\n",
      "Epoch 62/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7056 - loss: 0.6938 - val_accuracy: 0.6763 - val_loss: 0.7535\n",
      "Epoch 63/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7081 - loss: 0.6908 - val_accuracy: 0.6770 - val_loss: 0.7522\n",
      "Epoch 64/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7079 - loss: 0.6924 - val_accuracy: 0.6768 - val_loss: 0.7526\n",
      "Epoch 65/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7109 - loss: 0.6894 - val_accuracy: 0.6798 - val_loss: 0.7536\n",
      "Epoch 66/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7115 - loss: 0.6854 - val_accuracy: 0.6799 - val_loss: 0.7538\n",
      "Epoch 67/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7129 - loss: 0.6859 - val_accuracy: 0.6786 - val_loss: 0.7528\n",
      "Epoch 68/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7134 - loss: 0.6821 - val_accuracy: 0.6758 - val_loss: 0.7561\n",
      "Epoch 69/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7139 - loss: 0.6829 - val_accuracy: 0.6796 - val_loss: 0.7547\n",
      "Epoch 70/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7156 - loss: 0.6804 - val_accuracy: 0.6758 - val_loss: 0.7555\n",
      "Epoch 71/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7151 - loss: 0.6773 - val_accuracy: 0.6768 - val_loss: 0.7571\n",
      "Epoch 72/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7172 - loss: 0.6759 - val_accuracy: 0.6754 - val_loss: 0.7592\n",
      "Epoch 73/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7183 - loss: 0.6748 - val_accuracy: 0.6772 - val_loss: 0.7605\n",
      "Epoch 74/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7213 - loss: 0.6733 - val_accuracy: 0.6779 - val_loss: 0.7594\n",
      "Epoch 75/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7213 - loss: 0.6712 - val_accuracy: 0.6784 - val_loss: 0.7603\n",
      "Epoch 76/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7213 - loss: 0.6686 - val_accuracy: 0.6796 - val_loss: 0.7591\n",
      "Epoch 77/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7218 - loss: 0.6721 - val_accuracy: 0.6773 - val_loss: 0.7603\n",
      "Epoch 78/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7214 - loss: 0.6635 - val_accuracy: 0.6778 - val_loss: 0.7621\n",
      "Epoch 79/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7225 - loss: 0.6664 - val_accuracy: 0.6762 - val_loss: 0.7627\n",
      "Epoch 80/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7252 - loss: 0.6634 - val_accuracy: 0.6813 - val_loss: 0.7638\n",
      "Epoch 81/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7302 - loss: 0.6598 - val_accuracy: 0.6778 - val_loss: 0.7651\n",
      "Epoch 82/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7275 - loss: 0.6615 - val_accuracy: 0.6755 - val_loss: 0.7668\n",
      "Epoch 83/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7277 - loss: 0.6567 - val_accuracy: 0.6768 - val_loss: 0.7688\n",
      "Epoch 84/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7311 - loss: 0.6577 - val_accuracy: 0.6761 - val_loss: 0.7671\n",
      "Epoch 85/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7338 - loss: 0.6529 - val_accuracy: 0.6741 - val_loss: 0.7719\n",
      "Epoch 86/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7310 - loss: 0.6534 - val_accuracy: 0.6760 - val_loss: 0.7717\n",
      "Epoch 87/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7309 - loss: 0.6558 - val_accuracy: 0.6747 - val_loss: 0.7733\n",
      "Epoch 88/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.7332 - loss: 0.6517 - val_accuracy: 0.6749 - val_loss: 0.7745\n",
      "Epoch 89/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7381 - loss: 0.6472 - val_accuracy: 0.6751 - val_loss: 0.7747\n",
      "Epoch 90/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7343 - loss: 0.6459 - val_accuracy: 0.6762 - val_loss: 0.7774\n",
      "Epoch 91/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7392 - loss: 0.6450 - val_accuracy: 0.6766 - val_loss: 0.7771\n",
      "Epoch 92/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7389 - loss: 0.6442 - val_accuracy: 0.6758 - val_loss: 0.7766\n",
      "Epoch 93/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.7415 - loss: 0.6402 - val_accuracy: 0.6763 - val_loss: 0.7772\n",
      "Epoch 94/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7412 - loss: 0.6420 - val_accuracy: 0.6707 - val_loss: 0.7805\n",
      "Epoch 95/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7407 - loss: 0.6398 - val_accuracy: 0.6741 - val_loss: 0.7804\n",
      "Epoch 96/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7395 - loss: 0.6399 - val_accuracy: 0.6742 - val_loss: 0.7820\n",
      "Epoch 97/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7407 - loss: 0.6373 - val_accuracy: 0.6733 - val_loss: 0.7825\n",
      "Epoch 98/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7434 - loss: 0.6342 - val_accuracy: 0.6708 - val_loss: 0.7882\n",
      "Epoch 99/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7431 - loss: 0.6326 - val_accuracy: 0.6711 - val_loss: 0.7860\n",
      "Epoch 100/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7454 - loss: 0.6305 - val_accuracy: 0.6729 - val_loss: 0.7880\n",
      "Epoch 101/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7506 - loss: 0.6275 - val_accuracy: 0.6736 - val_loss: 0.7916\n",
      "Epoch 102/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7490 - loss: 0.6277 - val_accuracy: 0.6722 - val_loss: 0.7950\n",
      "Epoch 103/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7488 - loss: 0.6275 - val_accuracy: 0.6754 - val_loss: 0.7917\n",
      "Epoch 104/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7539 - loss: 0.6220 - val_accuracy: 0.6758 - val_loss: 0.7959\n",
      "Epoch 105/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7532 - loss: 0.6227 - val_accuracy: 0.6704 - val_loss: 0.7973\n",
      "Epoch 106/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7468 - loss: 0.6251 - val_accuracy: 0.6717 - val_loss: 0.8002\n",
      "Epoch 107/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7533 - loss: 0.6217 - val_accuracy: 0.6732 - val_loss: 0.7991\n",
      "Epoch 108/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7523 - loss: 0.6209 - val_accuracy: 0.6720 - val_loss: 0.7990\n",
      "Epoch 109/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7544 - loss: 0.6183 - val_accuracy: 0.6738 - val_loss: 0.7998\n",
      "Epoch 110/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7568 - loss: 0.6135 - val_accuracy: 0.6747 - val_loss: 0.8031\n",
      "Epoch 111/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7580 - loss: 0.6123 - val_accuracy: 0.6760 - val_loss: 0.8034\n",
      "Epoch 112/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7607 - loss: 0.6110 - val_accuracy: 0.6752 - val_loss: 0.8041\n",
      "Epoch 113/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7610 - loss: 0.6113 - val_accuracy: 0.6699 - val_loss: 0.8057\n",
      "Epoch 114/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7634 - loss: 0.6031 - val_accuracy: 0.6726 - val_loss: 0.8060\n",
      "Epoch 115/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7585 - loss: 0.6112 - val_accuracy: 0.6712 - val_loss: 0.8093\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu',),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),  # Reduced learning rate\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping with patience and best weight restoration\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               patience=35,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=1024,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m),\n\u001b[1;32m     26\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m\u001b[43mX_train_scaled\u001b[49m,\n\u001b[1;32m     32\u001b[0m                     y\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m     33\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     34\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m260\u001b[39m,\n\u001b[1;32m     35\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # Model architecture\n",
    "# final_model = Sequential([\n",
    "#     Input(shape=(X_train.shape[1],)),\n",
    "#     Dense(256, activation='relu',),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.35),\n",
    "\n",
    "#     Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "#     BatchNormalization(),\n",
    "\n",
    "#     Dense(256, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.1),\n",
    "\n",
    "#     Dense(256, activation='relu'),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.1),\n",
    "\n",
    "#     Dense(3, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Model compilation\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# # Model training\n",
    "# history = model.fit(x=X_train_scaled,\n",
    "#                     y=y_train,\n",
    "#                     batch_size=1024,\n",
    "#                     epochs=260,\n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(scaler.transform(df_test.drop(['ID'],axis=1)))\n",
    "pred_class = test_predictions.argmax(axis=1)\n",
    "pd.DataFrame({\n",
    "    'ID' : df_test['ID'],\n",
    "    'Predicted' : encoder_final.inverse_transform(pred_class.reshape(-1,1)).reshape(-1)\n",
    "}).to_csv('sub_ann.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
