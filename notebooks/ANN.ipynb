{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder,OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('../input/credit-dset/clean_trained.csv')\n",
    "df_test = pd.read_csv('../input/credit-dset/test_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encode_cols = ['Month','Profession']\n",
    "for i in one_hot_encode_cols:\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    encoded_train = ohe.fit_transform(df_train[[i]])\n",
    "    encoded_test = ohe.transform(df_test[[i]])\n",
    "    encoded_cols = [f\"{i}_{j}\" for j in ohe.categories_[0]]\n",
    "    df_train_encoded = pd.DataFrame(encoded_train, columns=encoded_cols)\n",
    "    df_test_encoded = pd.DataFrame(encoded_test, columns=encoded_cols)\n",
    "    df_train = pd.concat([df_train, df_train_encoded], axis=1).drop(columns=[i])\n",
    "    df_test = pd.concat([df_test, df_test_encoded], axis=1).drop(columns=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_mix_dict = {\"Bad\" : 0,\"Standard\" : 1,\"Good\" : 2}\n",
    "df_train['Credit_Mix'] = df_train['Credit_Mix'].map(cred_mix_dict)\n",
    "df_test['Credit_Mix'] = df_test['Credit_Mix'].map(cred_mix_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['pay_type','val_pay']] = df_train['Payment_Behaviour'].str.split(pat = '_spent_',n=1,expand = True)\n",
    "df_test[['pay_type','val_pay']] = df_test['Payment_Behaviour'].str.split(pat = '_spent_',n=1,expand = True)\n",
    "df_train = df_train.drop(['Payment_Behaviour'],axis=1)\n",
    "df_test = df_test.drop(['Payment_Behaviour'],axis=1)\n",
    "pay_type_dict = {'Low' : 0, 'High' : 1}\n",
    "val_pay_dict = {'Small_value_payments' : 0,'Medium_value_payments' : 1,'Large_value_payments' : 2}\n",
    "df_train['pay_type'] = df_train['pay_type'].map(pay_type_dict)\n",
    "df_test['pay_type'] = df_test['pay_type'].map(pay_type_dict)\n",
    "df_train['val_pay'] = df_train['val_pay'].map(val_pay_dict)\n",
    "df_test['val_pay'] = df_test['val_pay'].map(val_pay_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_dict = {'Yes' : 1,'No' : 0}\n",
    "df_train['Payment_of_Min_Amount'] = df_train['Payment_of_Min_Amount'].map(yes_no_dict)\n",
    "df_test['Payment_of_Min_Amount'] = df_test['Payment_of_Min_Amount'].map(yes_no_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final = OrdinalEncoder(categories=[['Poor', 'Standard', 'Good']])\n",
    "df_train['Credit_Score'] = encoder_final.fit_transform(df_train[['Credit_Score']])\n",
    "df_train['Credit_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['Credit_Score','Number'],axis=1)\n",
    "Y = df_train['Credit_Score']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_test=df_test.drop(['Number'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = X_scaled.reshape(-1, X_scaled.shape[1], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.4646 - loss: 1.8371 - val_accuracy: 0.5760 - val_loss: 1.5279\n",
      "Epoch 2/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.5729 - loss: 1.5185 - val_accuracy: 0.6006 - val_loss: 1.4207\n",
      "Epoch 3/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.6096 - loss: 1.4316 - val_accuracy: 0.6288 - val_loss: 1.3372\n",
      "Epoch 4/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6264 - loss: 1.3724 - val_accuracy: 0.6472 - val_loss: 1.2940\n",
      "Epoch 5/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6351 - loss: 1.3352 - val_accuracy: 0.6556 - val_loss: 1.2639\n",
      "Epoch 6/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6367 - loss: 1.3028 - val_accuracy: 0.6591 - val_loss: 1.2457\n",
      "Epoch 7/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6429 - loss: 1.2769 - val_accuracy: 0.6636 - val_loss: 1.2243\n",
      "Epoch 8/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6489 - loss: 1.2511 - val_accuracy: 0.6661 - val_loss: 1.2025\n",
      "Epoch 9/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6526 - loss: 1.2275 - val_accuracy: 0.6652 - val_loss: 1.1840\n",
      "Epoch 10/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6573 - loss: 1.2009 - val_accuracy: 0.6697 - val_loss: 1.1643\n",
      "Epoch 11/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6560 - loss: 1.1830 - val_accuracy: 0.6690 - val_loss: 1.1470\n",
      "Epoch 12/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6584 - loss: 1.1595 - val_accuracy: 0.6707 - val_loss: 1.1259\n",
      "Epoch 13/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6626 - loss: 1.1399 - val_accuracy: 0.6716 - val_loss: 1.1088\n",
      "Epoch 14/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6671 - loss: 1.1168 - val_accuracy: 0.6721 - val_loss: 1.0901\n",
      "Epoch 15/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6610 - loss: 1.0992 - val_accuracy: 0.6729 - val_loss: 1.0724\n",
      "Epoch 16/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6670 - loss: 1.0790 - val_accuracy: 0.6739 - val_loss: 1.0525\n",
      "Epoch 17/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6703 - loss: 1.0536 - val_accuracy: 0.6764 - val_loss: 1.0343\n",
      "Epoch 18/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6719 - loss: 1.0394 - val_accuracy: 0.6744 - val_loss: 1.0179\n",
      "Epoch 19/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6726 - loss: 1.0177 - val_accuracy: 0.6754 - val_loss: 1.0009\n",
      "Epoch 20/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6747 - loss: 0.9980 - val_accuracy: 0.6762 - val_loss: 0.9834\n",
      "Epoch 21/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6741 - loss: 0.9815 - val_accuracy: 0.6747 - val_loss: 0.9668\n",
      "Epoch 22/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6787 - loss: 0.9594 - val_accuracy: 0.6764 - val_loss: 0.9520\n",
      "Epoch 23/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6802 - loss: 0.9409 - val_accuracy: 0.6783 - val_loss: 0.9342\n",
      "Epoch 24/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6793 - loss: 0.9259 - val_accuracy: 0.6782 - val_loss: 0.9199\n",
      "Epoch 25/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6796 - loss: 0.9122 - val_accuracy: 0.6772 - val_loss: 0.9055\n",
      "Epoch 26/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6811 - loss: 0.8945 - val_accuracy: 0.6759 - val_loss: 0.8916\n",
      "Epoch 27/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.6798 - loss: 0.8829 - val_accuracy: 0.6775 - val_loss: 0.8783\n",
      "Epoch 28/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6833 - loss: 0.8637 - val_accuracy: 0.6788 - val_loss: 0.8668\n",
      "Epoch 29/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6836 - loss: 0.8542 - val_accuracy: 0.6761 - val_loss: 0.8569\n",
      "Epoch 30/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6843 - loss: 0.8401 - val_accuracy: 0.6759 - val_loss: 0.8437\n",
      "Epoch 31/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6878 - loss: 0.8294 - val_accuracy: 0.6778 - val_loss: 0.8346\n",
      "Epoch 32/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6883 - loss: 0.8178 - val_accuracy: 0.6752 - val_loss: 0.8255\n",
      "Epoch 33/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6853 - loss: 0.8077 - val_accuracy: 0.6780 - val_loss: 0.8173\n",
      "Epoch 34/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6870 - loss: 0.7993 - val_accuracy: 0.6766 - val_loss: 0.8103\n",
      "Epoch 35/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6870 - loss: 0.7906 - val_accuracy: 0.6771 - val_loss: 0.8031\n",
      "Epoch 36/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6875 - loss: 0.7808 - val_accuracy: 0.6776 - val_loss: 0.7980\n",
      "Epoch 37/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6894 - loss: 0.7744 - val_accuracy: 0.6771 - val_loss: 0.7911\n",
      "Epoch 38/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6919 - loss: 0.7680 - val_accuracy: 0.6781 - val_loss: 0.7874\n",
      "Epoch 39/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6926 - loss: 0.7607 - val_accuracy: 0.6786 - val_loss: 0.7824\n",
      "Epoch 40/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6875 - loss: 0.7562 - val_accuracy: 0.6766 - val_loss: 0.7776\n",
      "Epoch 41/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6928 - loss: 0.7492 - val_accuracy: 0.6771 - val_loss: 0.7743\n",
      "Epoch 42/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.6920 - loss: 0.7487 - val_accuracy: 0.6776 - val_loss: 0.7732\n",
      "Epoch 43/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6937 - loss: 0.7409 - val_accuracy: 0.6787 - val_loss: 0.7678\n",
      "Epoch 44/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6918 - loss: 0.7384 - val_accuracy: 0.6773 - val_loss: 0.7674\n",
      "Epoch 45/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6961 - loss: 0.7345 - val_accuracy: 0.6766 - val_loss: 0.7622\n",
      "Epoch 46/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.6943 - loss: 0.7312 - val_accuracy: 0.6770 - val_loss: 0.7606\n",
      "Epoch 47/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6955 - loss: 0.7265 - val_accuracy: 0.6791 - val_loss: 0.7608\n",
      "Epoch 48/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6978 - loss: 0.7225 - val_accuracy: 0.6779 - val_loss: 0.7601\n",
      "Epoch 49/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7008 - loss: 0.7187 - val_accuracy: 0.6768 - val_loss: 0.7581\n",
      "Epoch 50/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7007 - loss: 0.7172 - val_accuracy: 0.6757 - val_loss: 0.7565\n",
      "Epoch 51/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6985 - loss: 0.7171 - val_accuracy: 0.6774 - val_loss: 0.7542\n",
      "Epoch 52/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.6965 - loss: 0.7159 - val_accuracy: 0.6766 - val_loss: 0.7520\n",
      "Epoch 53/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7006 - loss: 0.7103 - val_accuracy: 0.6778 - val_loss: 0.7532\n",
      "Epoch 54/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7015 - loss: 0.7075 - val_accuracy: 0.6746 - val_loss: 0.7518\n",
      "Epoch 55/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7038 - loss: 0.7076 - val_accuracy: 0.6775 - val_loss: 0.7528\n",
      "Epoch 56/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7020 - loss: 0.7070 - val_accuracy: 0.6772 - val_loss: 0.7536\n",
      "Epoch 57/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7028 - loss: 0.7021 - val_accuracy: 0.6765 - val_loss: 0.7510\n",
      "Epoch 58/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7034 - loss: 0.6999 - val_accuracy: 0.6771 - val_loss: 0.7511\n",
      "Epoch 59/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7026 - loss: 0.6997 - val_accuracy: 0.6796 - val_loss: 0.7511\n",
      "Epoch 60/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7048 - loss: 0.6990 - val_accuracy: 0.6767 - val_loss: 0.7514\n",
      "Epoch 61/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7052 - loss: 0.6946 - val_accuracy: 0.6773 - val_loss: 0.7522\n",
      "Epoch 62/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7118 - loss: 0.6927 - val_accuracy: 0.6787 - val_loss: 0.7520\n",
      "Epoch 63/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7058 - loss: 0.6937 - val_accuracy: 0.6757 - val_loss: 0.7510\n",
      "Epoch 64/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7076 - loss: 0.6893 - val_accuracy: 0.6766 - val_loss: 0.7523\n",
      "Epoch 65/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7094 - loss: 0.6875 - val_accuracy: 0.6769 - val_loss: 0.7524\n",
      "Epoch 66/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7128 - loss: 0.6873 - val_accuracy: 0.6775 - val_loss: 0.7506\n",
      "Epoch 67/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7116 - loss: 0.6838 - val_accuracy: 0.6760 - val_loss: 0.7540\n",
      "Epoch 68/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7133 - loss: 0.6828 - val_accuracy: 0.6759 - val_loss: 0.7527\n",
      "Epoch 69/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7143 - loss: 0.6795 - val_accuracy: 0.6779 - val_loss: 0.7547\n",
      "Epoch 70/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7146 - loss: 0.6816 - val_accuracy: 0.6793 - val_loss: 0.7531\n",
      "Epoch 71/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7174 - loss: 0.6772 - val_accuracy: 0.6771 - val_loss: 0.7566\n",
      "Epoch 72/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7131 - loss: 0.6761 - val_accuracy: 0.6776 - val_loss: 0.7587\n",
      "Epoch 73/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7149 - loss: 0.6778 - val_accuracy: 0.6750 - val_loss: 0.7574\n",
      "Epoch 74/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7167 - loss: 0.6734 - val_accuracy: 0.6771 - val_loss: 0.7588\n",
      "Epoch 75/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7208 - loss: 0.6715 - val_accuracy: 0.6768 - val_loss: 0.7632\n",
      "Epoch 76/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7216 - loss: 0.6700 - val_accuracy: 0.6796 - val_loss: 0.7601\n",
      "Epoch 77/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7209 - loss: 0.6700 - val_accuracy: 0.6791 - val_loss: 0.7620\n",
      "Epoch 78/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7208 - loss: 0.6669 - val_accuracy: 0.6779 - val_loss: 0.7643\n",
      "Epoch 79/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7217 - loss: 0.6672 - val_accuracy: 0.6776 - val_loss: 0.7626\n",
      "Epoch 80/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7256 - loss: 0.6619 - val_accuracy: 0.6783 - val_loss: 0.7627\n",
      "Epoch 81/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7244 - loss: 0.6617 - val_accuracy: 0.6778 - val_loss: 0.7631\n",
      "Epoch 82/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7263 - loss: 0.6632 - val_accuracy: 0.6759 - val_loss: 0.7655\n",
      "Epoch 83/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7282 - loss: 0.6601 - val_accuracy: 0.6777 - val_loss: 0.7675\n",
      "Epoch 84/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7291 - loss: 0.6559 - val_accuracy: 0.6726 - val_loss: 0.7705\n",
      "Epoch 85/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7303 - loss: 0.6580 - val_accuracy: 0.6725 - val_loss: 0.7717\n",
      "Epoch 86/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7282 - loss: 0.6561 - val_accuracy: 0.6755 - val_loss: 0.7731\n",
      "Epoch 87/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7283 - loss: 0.6553 - val_accuracy: 0.6754 - val_loss: 0.7732\n",
      "Epoch 88/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7301 - loss: 0.6548 - val_accuracy: 0.6766 - val_loss: 0.7760\n",
      "Epoch 89/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7362 - loss: 0.6476 - val_accuracy: 0.6769 - val_loss: 0.7746\n",
      "Epoch 90/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7325 - loss: 0.6506 - val_accuracy: 0.6747 - val_loss: 0.7765\n",
      "Epoch 91/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7366 - loss: 0.6463 - val_accuracy: 0.6746 - val_loss: 0.7738\n",
      "Epoch 92/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7330 - loss: 0.6481 - val_accuracy: 0.6741 - val_loss: 0.7772\n",
      "Epoch 93/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7338 - loss: 0.6458 - val_accuracy: 0.6754 - val_loss: 0.7782\n",
      "Epoch 94/500\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7370 - loss: 0.6442 - val_accuracy: 0.6752 - val_loss: 0.7817\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu',),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),  # Reduced learning rate\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping with patience and best weight restoration\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               patience=35,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=1024,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Model architecture\n",
    "final_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu',),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Model training\n",
    "history = model.fit(x=X_train_scaled,\n",
    "                    y=y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=260,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
