{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "# Sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# TensorFlow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/clean_trained_outlier.csv')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/test_cleaned_outlier.csv')\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()   #Encoding the target variable in the training data\n",
    "train_df['Credit_Score'] = label_encoder.fit_transform(train_df['Credit_Score'])\n",
    "\n",
    "label_encode_cols = ['Month', 'Profession', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']  # Columns to label encode\n",
    "\n",
    "for col in label_encode_cols:    # Applying label encoding to each specified column\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "\n",
    "X = train_df.drop(columns=['Credit_Score'])  # Exclude target and unnecessary columns\n",
    "y = train_df['Credit_Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05,\n",
    "                                                    stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu',),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),  # Reduced learning rate\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping with patience and best weight restoration\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               patience=35,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train_scaled,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    batch_size=1024,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Model architecture\n",
    "final_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(256, activation='relu',),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(512, activation='relu', kernel_regularizer=l1(1e-4)),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model compilation\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Model training\n",
    "history = model.fit(x=X_train_scaled,\n",
    "                    y=y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=260,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
