{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitta\\AppData\\Local\\Temp\\ipykernel_28736\\3538755282.py:14: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"input/credit-dset/train.csv\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df_train = pd.read_csv(\"input/credit-dset/train.csv\")\n",
    "df_test = pd.read_csv(\"input/credit-dset/test.csv\")\n",
    "\n",
    "# Columns for numerical conversion\n",
    "columns_to_convert = [\n",
    "    'Income_Annual', 'Base_Salary_PerMonth', 'Rate_Of_Interest', \n",
    "    'Credit_Limit', 'Current_Debt_Outstanding', 'Ratio_Credit_Utilization', \n",
    "    'Per_Month_EMI', 'Monthly_Investment', 'Monthly_Balance'\n",
    "]\n",
    "int_columns_to_convert = [\n",
    "    'Age', 'Total_Bank_Accounts', 'Rate_Of_Interest', \n",
    "    'Total_Current_Loans', 'Delay_from_due_date', 'Total_Delayed_Payments'\n",
    "]\n",
    "\n",
    "# Convert columns to numeric and handle invalid entries\n",
    "df_train[columns_to_convert] = df_train[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "df_train[int_columns_to_convert] = df_train[int_columns_to_convert].apply(pd.to_numeric, errors='coerce').astype('Int64')\n",
    "\n",
    "# Apply similar conversions to the test set\n",
    "df_test[columns_to_convert] = df_test[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "df_test[int_columns_to_convert] = df_test[int_columns_to_convert].apply(pd.to_numeric, errors='coerce').astype('Int64')\n",
    "\n",
    "# Fix outliers and invalid values in train set\n",
    "df_train['Age'] = df_train['Age'].apply(lambda x: x if 0 <= x <= 100 else np.nan)\n",
    "df_train['Total_Bank_Accounts'] = df_train['Total_Bank_Accounts'].apply(lambda x: x if x > 0 else np.nan)\n",
    "df_train['Total_Credit_Cards'] = df_train['Total_Credit_Cards'].apply(lambda x: x if x > 0 else np.nan)\n",
    "df_train['Rate_Of_Interest'] = df_train['Rate_Of_Interest'].apply(lambda x: x if x >= 0 else np.nan)\n",
    "\n",
    "# Generate new features\n",
    "for dataset in [df_train, df_test]:\n",
    "    dataset['Debt_Income_Ratio'] = dataset['Current_Debt_Outstanding'] / dataset['Income_Annual']\n",
    "    dataset['Income_Credit_Limit_Ratio'] = dataset['Income_Annual'] / dataset['Credit_Limit']\n",
    "    dataset['Debt_Credit_Limit_Ratio'] = dataset['Current_Debt_Outstanding'] / dataset['Credit_Limit']\n",
    "    dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute missing values with KNN Imputer\n",
    "numerical_features = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_train[numerical_features] = knn_imputer.fit_transform(df_train[numerical_features])\n",
    "df_test[numerical_features] = knn_imputer.transform(df_test[numerical_features])\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['Credit_Score'] = label_encoder.fit_transform(df_train['Credit_Score'])\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X = df_train.drop(columns='Credit_Score')\n",
    "y = df_train['Credit_Score']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessor for the pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Initialize classifiers\n",
    "xgb_model = XGBClassifier(learning_rate=0.05, max_depth=6, n_estimators=300, random_state=4, eval_metric='mlogloss')\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the pipeline for each classifier\n",
    "xgb_pipeline = Pipeline([('preprocessor', preprocessor), ('classifier', xgb_model)])\n",
    "rf_pipeline = Pipeline([('preprocessor', preprocessor), ('classifier', rf_model)])\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid_xgb = {\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__max_depth': [6],\n",
    "    'classifier__n_estimators': [100, 300]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 300],\n",
    "    'classifier__max_depth': [6, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search for both models\n",
    "grid_search_xgb = GridSearchCV(xgb_pipeline, param_grid_xgb, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_rf = GridSearchCV(rf_pipeline, param_grid_rf, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit models and get best estimator\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate both models on the validation set\n",
    "xgb_val_predictions = grid_search_xgb.best_estimator_.predict(X_val)\n",
    "rf_val_predictions = grid_search_rf.best_estimator_.predict(X_val)\n",
    "xgb_val_accuracy = accuracy_score(y_val, xgb_val_predictions)\n",
    "rf_val_accuracy = accuracy_score(y_val, rf_val_predictions)\n",
    "\n",
    "# Choose the model with the best validation accuracy\n",
    "if xgb_val_accuracy > rf_val_accuracy:\n",
    "    best_pipeline = grid_search_xgb.best_estimator_\n",
    "    print(\"Using XGBoost with accuracy:\", xgb_val_accuracy)\n",
    "else:\n",
    "    best_pipeline = grid_search_rf.best_estimator_\n",
    "    print(\"Using RandomForest with accuracy:\", rf_val_accuracy)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = best_pipeline.predict(df_test)\n",
    "test_predictions_labels = label_encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Prepare the submission file\n",
    "test_ids = df_test['ID'].copy()\n",
    "submission = pd.DataFrame({'ID': test_ids, 'Credit_Score': test_predictions_labels})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
